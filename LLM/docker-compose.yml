services:
  web:
    build:
      context: ./
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    command: ["python", "/app/manage.py", "runserver", "0.0.0.0:8000"]
    working_dir: /app

  frontend:
    build:
      context: ../frontend
    ports:
      - "8080:8080"
    command: ["npm", "run", "serve"]

  ollama:
    image: ollama/ollama:latest # Jeśli masz obraz Ollama dostępny
    ports:
      - "5000:5000" # Możesz wybrać odpowiedni port, na którym będzie działać Ollama
    command: [ "serve" ]
    environment:
      - MODEL=mistral:latest # Wybierz model do uruchomienia
